# HTML5 有关音视频的一些重要API

* AudioContext()

[https://developer.mozilla.org/zh-CN/docs/Web/API/AudioContext]()

>AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。
>

利用该对象下的一些方法，能够做到实现音频分析和音频输出，比如


* AudioContext.decodeAudioData()

可以对拿到的音频数据（来自文件，必须先将文件读入内存中）进行解码得到buffer数据,比如

```js
audioBox.decodeAudioData(fileResult, function (buffer) { // 对fileResult进行解码，解码后将buffer传入回调函数
		let audioSourceNode = audioBox.createBufferSource();//给盒子创建一个输入流
		let analyser = audioBox.createAnalyser() ; // 创建分析node
		audioSourceNode.buffer = buffer; //输入流引入 缓冲准备

```
其中的fileResult来自	`FileReader.readAsArrayBuffer(file)`,需要在`FileReader`的`onload`回调中进行

* AudioContext.createMediaElementSource()

可以从一些标签中获取音频数据得到一个buffer，比如可以

```js
let audio = new Audio();
	audio.src = audioSrc;
	let audioBox = new AudioContext(); // 申请一个音频容器，可以对数据进行解码
	let analyser = audioBox.createAnalyser();
	let source = audioBox.createMediaElementSource(audio);
	source.connect(analyser)
	analyser.connect(audioBox.destination)

```

* AudioContext.createAnalyser()

可以创建出一个用于分析音频的分析器，可以得到频域，用于得到当前的声音强度等数据，如：

```js
let analyser = audioBox.createAnalyser() ; // 创建分析node
			audioSourceNode.buffer = buffer; //输入流引入 缓冲准备
			audioSourceNode.connect(analyser); // 链接上音频分析
			analyser.connect(audioBox.destination); // 连接上音频输出

```



有关getUserMedia
--

[https://developer.mozilla.org/zh-CN/docs/Web/API/MediaDevices/getUserMedia]()

用法：

```js
navigator.mediaDevices.getUserMedia(constraints)
.then(function(mediaStream) { ... })
.catch(function(error) { ... })
```

`then`里面回调的data是`stream`，所以可以把这个`stream`接入`audioCtx.createMediaStreamSource(stream)`,然后再将其连接上`analyser`，就可以做上述的数据分析和可视化操作。

比如：

```js
let constraints = {
	video:true,
	audio:true
}

navigator.mediaDevices.getUserMedia(constraints).then(
（stream)=>{
	let audioCtx = new AudioContext()
	let source = audioCtx.createMediaStreamSource(stream)
	stream = stream.getAudioTracks()
	let analyser = audioCtx.createAnalyser()
	source.connect(analyser)
	analyser.fftSize = 1024
	let array= new Uint8Array(analyser.frequencyBinCount)
	let animation = ()=>{
		analyser.getByteFrequencyData(array)
		console.log(array)
		requestAnimationFrame(animation)
	}
	requestAnimationFrame(animation)
})
```
这样就可以形成一个拿到麦克风输入流并输出频域数组的功能